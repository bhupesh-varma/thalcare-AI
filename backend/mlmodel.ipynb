{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217012be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/5e/23/f8b28ca248bb629b9e08f877dd2965d1994e1674a03d67cd10c5246da248/lightgbm-4.6.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\thal-ai\\thalcare-ai\\venv\\lib\\site-packages (from lightgbm) (2.3.4)\n",
      "Requirement already satisfied: scipy in d:\\thal-ai\\thalcare-ai\\venv\\lib\\site-packages (from lightgbm) (1.16.2)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 0.8/1.5 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 22.9 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a9abefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc54d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved encoder: D:\\Thal-AI\\thalcare-AI\\backend\\output_api\\encoders_api\\enc_Blood_Group_Requested.pkl\n",
      "✅ Saved encoder: D:\\Thal-AI\\thalcare-AI\\backend\\output_api\\encoders_api\\enc_Urgency_Level.pkl\n",
      "✅ Saved encoder: D:\\Thal-AI\\thalcare-AI\\backend\\output_api\\encoders_api\\enc_City.pkl\n",
      "✅ Saved features list: D:\\Thal-AI\\thalcare-AI\\backend\\output_api\\features_api.json\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1950\n",
      "[LightGBM] [Info] Number of data points in the train set: 7578, number of used features: 15\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@3: 0.668333\tvalid_0's ndcg@5: 0.696564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's ndcg@3: 0.661163\tvalid_0's ndcg@5: 0.684759\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's ndcg@3: 0.677206\tvalid_0's ndcg@5: 0.697986\n",
      "✅ Saved LightGBM model: D:\\Thal-AI\\thalcare-AI\\backend\\output_api\\ranker_api_aligned.txt\n",
      "✅ Saved sklearn wrapper model (joblib): D:\\Thal-AI\\thalcare-AI\\backend\\output_api\\ranker_api_aligned.pkl\n",
      "✅ Saved manifest: D:\\Thal-AI\\thalcare-AI\\backend\\output_api\\manifest.json\n",
      "Best iteration: 9\n",
      "NDCG@3:  0.6779\n",
      "NDCG@5:  0.6979\n",
      "NDCG@10: 0.8159\n",
      "✅ Saved feature importance: D:\\Thal-AI\\thalcare-AI\\backend\\output_api\\feature_importance.json\n",
      "[('Rel_Distance', 2829.71607221663), ('Distance_km', 1653.1525871753693), ('Inv_Distance', 1559.6537709534168), ('Last_Updated_Min_Ago', 1004.7979336678982), ('Rel_Availability', 853.6202109009027), ('Availability_Ratio', 602.247102484107), ('Staleness_Score', 282.03175711631775), ('Available_Units_For_Type', 267.99151235818863), ('Urgency_x_Distance', 265.42469388246536), ('City', 169.10793149471283), ('Blood_Group_Requested', 104.84797066450119), ('Units_Requested', 30.71115005016327), ('Meets_Demand_Bool', 0.0), ('Urgency_Level', 0.0), ('Urgency_Num', 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thal-AI\\thalcare-AI\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py:861: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    }
   ],
   "source": [
    "# save as train_ranker.py and run in the same env as your original\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import ndcg_score\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "# ============================================================\n",
    "#  CONFIG\n",
    "# ============================================================\n",
    "DATA_PATH = r\"D:\\Thal-AI\\thalcare-AI\\backend\\blood_request_ranking_dataset.csv\"\n",
    "OUTPUT_DIR = r\"D:\\Thal-AI\\thalcare-AI\\backend\\output_api\"\n",
    "ENC_DIR = os.path.join(OUTPUT_DIR, \"encoders_api\")\n",
    "MODEL_PATH = os.path.join(OUTPUT_DIR, \"ranker_api_aligned.txt\")   # LightGBM booster save\n",
    "PICKLE_MODEL = os.path.join(OUTPUT_DIR, \"ranker_api_aligned.pkl\") # optional joblib\n",
    "FEATURES_PATH = os.path.join(OUTPUT_DIR, \"features_api.json\")\n",
    "MANIFEST_PATH = os.path.join(OUTPUT_DIR, \"manifest.json\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(ENC_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "#  LOAD DATA\n",
    "# ============================================================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# graded relevance: 2 (fulfilled) > 1 (chosen) > 0\n",
    "df[\"Relevance\"] = np.where(\n",
    "    df[\"Was_Fulfilled\"] == 1, 2,\n",
    "    np.where(df[\"Was_Chosen_By_User\"] == 1, 1, 0)\n",
    ").astype(int)\n",
    "\n",
    "# ============================================================\n",
    "#  FEATURE ENGINEERING (your existing features)\n",
    "# ============================================================\n",
    "df[\"Availability_Ratio\"] = df[\"Available_Units_For_Type\"] / df[\"Units_Requested\"].clip(lower=1)\n",
    "df[\"Staleness_Score\"] = 1.0 / (1.0 + df[\"Last_Updated_Min_Ago\"])\n",
    "g = df.groupby(\"Request_ID\", sort=False)\n",
    "df[\"Rel_Availability\"] = df[\"Available_Units_For_Type\"] / g[\"Available_Units_For_Type\"].transform(\"mean\").clip(lower=1e-6)\n",
    "df[\"Rel_Distance\"] = df[\"Distance_km\"] / (g[\"Distance_km\"].transform(\"min\") + 1e-6)\n",
    "df[\"Inv_Distance\"] = 1.0 / (1.0 + df[\"Distance_km\"])\n",
    "df[\"Urgency_Num\"] = df[\"Urgency_Level\"].map({\"Emergency\": 2, \"Routine\": 1, \"Scheduled\": 0}).fillna(1).astype(int)\n",
    "df[\"Urgency_x_Distance\"] = df[\"Urgency_Num\"] * df[\"Distance_km\"]\n",
    "\n",
    "features = [\n",
    "    \"Distance_km\", \"Available_Units_For_Type\", \"Meets_Demand_Bool\",\n",
    "    \"Last_Updated_Min_Ago\", \"Units_Requested\", \"Blood_Group_Requested\",\n",
    "    \"Urgency_Level\", \"City\", \"Availability_Ratio\", \"Staleness_Score\",\n",
    "    \"Rel_Availability\", \"Rel_Distance\", \"Inv_Distance\", \"Urgency_Num\",\n",
    "    \"Urgency_x_Distance\",\n",
    "]\n",
    "label = \"Relevance\"\n",
    "\n",
    "# ============================================================\n",
    "#  ENCODING (LabelEncoder approach but persisted)\n",
    "#  Alternative: use LightGBM categorical_feature instead of encoding\n",
    "# ============================================================\n",
    "encoders = {}\n",
    "categorical_cols = [\"Blood_Group_Requested\", \"Urgency_Level\", \"City\"]\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # fillna and cast to str to avoid issues\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    encoders[col] = le\n",
    "    enc_path = os.path.join(ENC_DIR, f\"enc_{col}.pkl\")\n",
    "    joblib.dump(le, enc_path)\n",
    "    print(f\"✅ Saved encoder: {enc_path}\")\n",
    "\n",
    "# Persist features list\n",
    "with open(FEATURES_PATH, \"w\") as f:\n",
    "    json.dump(features, f)\n",
    "print(\"✅ Saved features list:\", FEATURES_PATH)\n",
    "\n",
    "# ============================================================\n",
    "#  TRAIN / TEST SPLIT (by Request_ID)\n",
    "# ============================================================\n",
    "req_ids = df[\"Request_ID\"].unique()\n",
    "train_ids, test_ids = train_test_split(req_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = df[df[\"Request_ID\"].isin(train_ids)].copy()\n",
    "test_df = df[df[\"Request_ID\"].isin(test_ids)].copy()\n",
    "\n",
    "# Optionally: keep only groups with at least 2 candidates and >=1 positive\n",
    "def keep_valid_groups(d, label_col):\n",
    "    gsize = d.groupby(\"Request_ID\").size()\n",
    "    gpos = d.groupby(\"Request_ID\")[label_col].sum()\n",
    "    good = gsize[(gsize >= 2) & (gpos >= 1)].index\n",
    "    return d[d[\"Request_ID\"].isin(good)].copy()\n",
    "\n",
    "train_df = keep_valid_groups(train_df, label)\n",
    "test_df = keep_valid_groups(test_df, label)\n",
    "\n",
    "# ============================================================\n",
    "#  CRITICAL: Sort by Request_ID so LightGBM group sizes align to row order\n",
    "# ============================================================\n",
    "train_df = train_df.sort_values(\"Request_ID\").reset_index(drop=True)\n",
    "test_df = test_df.sort_values(\"Request_ID\").reset_index(drop=True)\n",
    "\n",
    "# Build groups AFTER sorting\n",
    "group_train = train_df.groupby(\"Request_ID\").size().to_list()\n",
    "group_test  = test_df.groupby(\"Request_ID\").size().to_list()\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[label].astype(int)\n",
    "X_test,  y_test  = test_df[features], test_df[label].astype(int)\n",
    "\n",
    "# Optional sample weights (e.g., upweight fulfilled)\n",
    "# sample_weight = np.where(train_df[\"Was_Fulfilled\"]==1, 2.0, 1.0)\n",
    "sample_weight = None\n",
    "\n",
    "# ============================================================\n",
    "#  TRAIN MODEL (LightGBM Ranker)\n",
    "# ============================================================\n",
    "ranker = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    eval_at=[3,5],\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=3000,\n",
    "    num_leaves=95,\n",
    "    min_child_samples=30,\n",
    "    colsample_bytree=0.9,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ranker.fit(\n",
    "    X_train, y_train,\n",
    "    group=group_train,\n",
    "    sample_weight=sample_weight,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[group_test],\n",
    "    callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=50)],\n",
    ")\n",
    "\n",
    "# Save the trained model (LightGBM booster format and joblib fallback)\n",
    "booster = ranker.booster_\n",
    "booster.save_model(MODEL_PATH)\n",
    "joblib.dump(ranker, PICKLE_MODEL)\n",
    "print(\"✅ Saved LightGBM model:\", MODEL_PATH)\n",
    "print(\"✅ Saved sklearn wrapper model (joblib):\", PICKLE_MODEL)\n",
    "\n",
    "# Save manifest (what we saved + version)\n",
    "manifest = {\n",
    "    \"model_booster\": MODEL_PATH,\n",
    "    \"model_joblib\": PICKLE_MODEL,\n",
    "    \"features\": FEATURES_PATH,\n",
    "    \"encoders_dir\": ENC_DIR,\n",
    "    \"training_rows\": int(len(train_df)),\n",
    "    \"test_rows\": int(len(test_df)),\n",
    "    \"best_iteration\": int(getattr(ranker, \"best_iteration_\", -1) or booster.best_iteration)\n",
    "}\n",
    "with open(MANIFEST_PATH, \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "print(\"✅ Saved manifest:\", MANIFEST_PATH)\n",
    "\n",
    "# ============================================================\n",
    "#  EVALUATION (grouped NDCG)\n",
    "# ============================================================\n",
    "def ndcg_grouped(y_true, y_score, group_sizes, k=5):\n",
    "    off = 0\n",
    "    s = []\n",
    "    for sz in group_sizes:\n",
    "        yt = y_true.iloc[off:off+sz].values\n",
    "        ys = y_score[off:off+sz]\n",
    "        # if all zeros in yt, ndcg_score returns 0 — that's fine\n",
    "        s.append(ndcg_score([yt],[ys], k=k))\n",
    "        off += sz\n",
    "    return float(np.mean(s))\n",
    "\n",
    "y_pred = ranker.predict(X_test, num_iteration=ranker.best_iteration_)\n",
    "print(f\"Best iteration: {getattr(ranker,'best_iteration_', -1)}\")\n",
    "print(f\"NDCG@3:  {ndcg_grouped(y_test, y_pred, group_test, k=3):.4f}\")\n",
    "print(f\"NDCG@5:  {ndcg_grouped(y_test, y_pred, group_test, k=5):.4f}\")\n",
    "print(f\"NDCG@10: {ndcg_grouped(y_test, y_pred, group_test, k=10):.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "#  Feature importance (save)\n",
    "# ============================================================\n",
    "fi = booster.feature_importance(importance_type=\"gain\")\n",
    "fi_names = booster.feature_name()\n",
    "feat_imp = sorted(zip(fi_names, fi.tolist()), key=lambda x: x[1], reverse=True)\n",
    "feat_imp_path = os.path.join(OUTPUT_DIR, \"feature_importance.json\")\n",
    "with open(feat_imp_path, \"w\") as f:\n",
    "    json.dump(feat_imp, f, indent=2)\n",
    "print(\"✅ Saved feature importance:\", feat_imp_path)\n",
    "print(feat_imp[:20])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
